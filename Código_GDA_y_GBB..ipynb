{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rWW4F0RLNLp"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# BIBLIOTECAS\n",
        "# ===============================================================\n",
        "import pycutest as pc # Biblioteca especializada para problemas de otimiza√ß√£o de teste\n",
        "import numpy as np # Computa√ß√£o num√©rica e opera√ß√µes matem√°ticas\n",
        "import time  # Medi√ß√£o de tempo de execu√ß√£o\n",
        "\n",
        "# ===============================================================\n",
        "# M√©todo Del Gradiente de Descenso com Armijo (Mon√≥tono)\n",
        "# ===============================================================\n",
        "def steepest_descent_armijo(p, x0,\n",
        "                            tau=1e-6,\n",
        "                            maxit=100000,\n",
        "                            c1=1e-4,\n",
        "                            rho=0.5,\n",
        "                            alpha = 1.0):\n",
        "    \"\"\"\n",
        "    Implementa√ß√£o do M√©todo de Descenso do Gradiente com Busca de Linha de Armijo (Mon√≥tono).\n",
        "    \"\"\"\n",
        "    # Ponto inicial\n",
        "    xk = x0.copy()\n",
        "\n",
        "    # Avalia√ß√£o inicial da fun√ß√£o e gradiente\n",
        "    fk, gk = p.obj(xk, gradient=True)\n",
        "    norm_g = np.linalg.norm(gk)\n",
        "    hist = [(0, fk, norm_g)]  # Hist√≥rico de itera√ß√µes\n",
        "\n",
        "    start_time = time.time() # Medi√ß√£o do tempo\n",
        "    f_evals = 1  # Contador de avalia√ß√µes da fun√ß√£o\n",
        "    g_evals = 1  # Contador de avalia√ß√µes do gradiente\n",
        "    line_searches = 0  # Contador de buscas de linha\n",
        "\n",
        "    # Loop principal de otimiza√ß√£o\n",
        "    for k in range(1, maxit + 1):\n",
        "        # Crit√©rio de Parada - verifica se o gradiente √© suficientemente pequeno\n",
        "        if norm_g <= tau * (1 + abs(fk)):\n",
        "            break\n",
        "\n",
        "        # Busca de Linha de Armijo\n",
        "        gTdk = -norm_g**2  # Produto interno gradiente √ó dire√ß√£o\n",
        "        inner_iter = 0\n",
        "        max_inner = 20000  # N√∫mero m√°ximo de itera√ß√µes internas\n",
        "\n",
        "        # Loop interno para ajuste do tamanho do passo\n",
        "        while inner_iter < max_inner:\n",
        "            x_new = xk - alpha * gk  # Nova tentativa de ponto\n",
        "            f_new = p.obj(x_new)  # Avalia fun√ß√£o no novo ponto\n",
        "            f_evals += 1\n",
        "\n",
        "            # Condi√ß√£o de Armijo - verifica decr√©scimo suficiente\n",
        "            if f_new <= fk + c1 * alpha * gTdk:\n",
        "                line_searches += 1\n",
        "                break  # Aceita o passo\n",
        "\n",
        "            alpha *= rho  # Reduz o tamanho do passo\n",
        "            inner_iter += 1\n",
        "\n",
        "            # Condi√ß√£o de passo m√≠nimo DENTRO do loop\n",
        "            if alpha < 1e-18:\n",
        "                break\n",
        "\n",
        "        # Atualiza√ß√£o das vari√°veis ap√≥s busca de linha\n",
        "        xk = x_new\n",
        "        fk, gk = p.obj(xk, gradient=True)\n",
        "        f_evals += 1\n",
        "        g_evals += 1\n",
        "        norm_g = np.linalg.norm(gk)\n",
        "        hist.append((k, fk, norm_g))  # Armazena hist√≥rico\n",
        "\n",
        "        # Condi√ß√£o de passo m√≠nimo FORA do loop (backup)\n",
        "        if alpha < 1e-18:\n",
        "            break\n",
        "\n",
        "        # Condi√ß√£o de m√°ximo de itera√ß√µes internas alcan√ßado\n",
        "        if inner_iter >= max_inner:\n",
        "            break\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return xk, fk, hist, elapsed_time, f_evals, g_evals, line_searches\n",
        "\n",
        "# ===============================================================\n",
        "# M√©todo Global Barzilai‚ÄìBorwein (Raydan, 1997)\n",
        "# ===============================================================\n",
        "def gbb_raydan(p, x0,\n",
        "               tau=1e-6,\n",
        "               epsilon=1e-10,\n",
        "               y = -1e-5,\n",
        "               maxit=100000,\n",
        "               M = 10,\n",
        "               gamma = 0.2,\n",
        "               alpha_k  = 1.0):\n",
        "    \"\"\"\n",
        "    Implementa√ß√£o do m√©todo Global Barzilai‚ÄìBorwein (GBB)\n",
        "    \"\"\"\n",
        "    # Ponto Inicial\n",
        "    xk = x0.copy()\n",
        "\n",
        "    # Avalia√ß√£o inicial da fun√ß√£o e gradiente\n",
        "    fk, gk = p.obj(xk, gradient=True)\n",
        "    fk_list = [fk]  # Lista para crit√©rio n√£o mon√≥tono\n",
        "    norm_g = np.linalg.norm(gk)\n",
        "    hist = [(0, fk, norm_g)] # Hist√≥rico de itera√ß√µes\n",
        "\n",
        "    start_time = time.time()\n",
        "    f_evals = 1\n",
        "    g_evals = 1\n",
        "    line_searches = 0\n",
        "    spectral_searches = 0  # Contador de buscas espectrais\n",
        "\n",
        "    # Loop principal do algoritmo GBB\n",
        "    for k in range(1, maxit + 1):\n",
        "        # Crit√©rio de Parada\n",
        "        if norm_g <= tau * (1 + abs(fk)):\n",
        "            break\n",
        "\n",
        "        if norm_g == 0:  # Gradiente exatamente zero\n",
        "            break\n",
        "\n",
        "        # Limita√ß√£o de alpha_k para evitar valores extremos\n",
        "        if alpha_k <= epsilon or alpha_k >= 1/epsilon:\n",
        "            delta = 1.0 if norm_g > 1.0 else (1.0/norm_g if 1e-5 <= norm_g <= 1.0 else 1e5)\n",
        "            alpha_k = delta\n",
        "\n",
        "        lamda = 1/alpha_k  # Par√¢metro do passo\n",
        "\n",
        "        # Crit√©rio de decr√©scimo n√£o mon√≥tono - usa hist√≥rico de M itera√ß√µes\n",
        "        min_k_M = min(k, M)\n",
        "        f_ref = np.max(fk_list[-min_k_M:])  # Valor de refer√™ncia\n",
        "\n",
        "        # Busca de linha - MANTENDO SUA ESTRUTURA ORIGINAL\n",
        "        r = 0  # Flag de aceita√ß√£o\n",
        "        inner_count = 0\n",
        "        max_inner = 20000  # Limite de seguran√ßa\n",
        "\n",
        "        # Loop interno de busca de linha\n",
        "        while r != 1 and inner_count < max_inner:\n",
        "            x_new = xk - lamda * gk\n",
        "            f_new = p.obj(x_new)\n",
        "            f_evals += 1\n",
        "\n",
        "            # Condi√ß√£o de aceita√ß√£o n√£o mon√≥tona\n",
        "            if f_new <= f_ref + y * lamda * norm_g**2:\n",
        "                # Aceitar o passo\n",
        "                lamda_k = lamda\n",
        "                g_new = p.grad(x_new)\n",
        "                g_evals += 1\n",
        "                y_km1 = g_new - gk  # Diferen√ßa de gradientes\n",
        "                spectral_searches += 1  # CONTADOR DE BUSCAS ESPECTRAIS\n",
        "\n",
        "                # C√°lculo de alpha_k (GBB) - ESTO √â UMA BUSCA ESPECTRAL\n",
        "                if np.dot(gk, gk) > 1e-12:  # Evita divis√£o por zero\n",
        "                    alpha_k = -(np.dot(gk, y_km1)) / (lamda_k * np.dot(gk, gk))\n",
        "\n",
        "                # Atualiza√ß√£o das vari√°veis\n",
        "                xk = x_new\n",
        "                fk = f_new\n",
        "                gk = g_new\n",
        "                norm_g = np.linalg.norm(gk)\n",
        "                fk_list.append(fk)\n",
        "                r = 1  # Sai do loop\n",
        "\n",
        "            else:\n",
        "                # Redu√ß√£o de passo - passo rejeitado\n",
        "                lamda *= gamma\n",
        "                alpha_k = 1.0 / lamda\n",
        "                line_searches += 1\n",
        "                r = 0  # Permanece no loop\n",
        "\n",
        "            inner_count += 1\n",
        "\n",
        "            # CONDI√á√ÉO CR√çTICA - DENTRO do loop interno\n",
        "            if alpha_k < 1e-18:  # Passo muito pequeno\n",
        "                break\n",
        "\n",
        "        # Verifica√ß√µes ap√≥s o loop interno\n",
        "        if inner_count >= max_inner:  # Muitas itera√ß√µes internas\n",
        "            break\n",
        "\n",
        "        if lamda < 1e-18:  # Passo insignificante\n",
        "            break\n",
        "\n",
        "        hist.append((k, fk, norm_g))  # Atualiza hist√≥rico\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return xk, fk, hist, elapsed_time, f_evals, g_evals, line_searches, spectral_searches\n",
        "\n",
        "# ===============================================================\n",
        "# Bloco principal de execu√ß√£o para PyCUTEst\n",
        "# ===============================================================\n",
        "def run_cutest_optimization(problema_nombre):\n",
        "    \"\"\"\n",
        "    Executa a otimiza√ß√£o usando a dimens√£o padr√£o do problema\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"#\"*60)\n",
        "    print(f\"## AVALIANDO PROBLEMA: {problema_nombre}\")\n",
        "    print(\"#\"*60)\n",
        "\n",
        "    try:\n",
        "        # S√ì usa import_problem - sem especificar dimens√£o\n",
        "        p = pc.import_problem(problema_nombre)\n",
        "        print(f\"Problema carregado com dimens√£o padr√£o\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar o problema {problema_nombre}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Informa√ß√£o do problema\n",
        "    x0 = p.x0  # Ponto inicial\n",
        "    dimension = p.n  # Dimens√£o do problema\n",
        "    f0, g0 = p.obj(x0, gradient=True)  # Avalia√ß√£o inicial\n",
        "\n",
        "    print(f\"Fun√ß√£o: {p.name}\")\n",
        "    print(f\"Dimens√£o do problema: {dimension}\")\n",
        "\n",
        "    # Armazenar resultados para an√°lise\n",
        "    results = []\n",
        "\n",
        "    # ------------------- Descenso Metodo do gradiente -------------------\n",
        "    try:\n",
        "        # Executa m√©todo Armijo\n",
        "        x_opt_arm, f_opt_arm, hist_arm, time_arm, f_evals_arm, g_evals_arm, ls_arm = steepest_descent_armijo(p, x0.copy())\n",
        "\n",
        "        final_iter_arm = len(hist_arm) - 1\n",
        "        final_norm_g_arm = hist_arm[-1][2] if hist_arm else float('inf')\n",
        "\n",
        "        # Determinar estado de converg√™ncia\n",
        "        if final_norm_g_arm <= 1e-6 * (1 + abs(f_opt_arm)):\n",
        "            convergence_arm = \"CONVERGIU\"\n",
        "        elif final_iter_arm >= 10000:\n",
        "            convergence_arm = \"EXCEDEU ITERA√á√ïES M√ÅXIMAS\"\n",
        "        elif hist_arm and hist_arm[-1][2] > 1e-3:\n",
        "            convergence_arm = \"GRADIENTE N√ÉO PR√ìXIMO DE ZERO\"\n",
        "        else:\n",
        "            convergence_arm = \"N√ÉO CONVERGIU\"\n",
        "\n",
        "        armijo_result = {\n",
        "            'method': 'Metodo do gradiente',\n",
        "            'iterations': final_iter_arm,\n",
        "            'time': time_arm,\n",
        "            'final_norm_g': final_norm_g_arm,\n",
        "            'final_f': f_opt_arm,\n",
        "            'convergence': convergence_arm,\n",
        "            'f_evals': f_evals_arm,\n",
        "            'g_evals': g_evals_arm,\n",
        "            'line_searches': ls_arm,  # BUSCAS LINEARES PARA METODO DO GRADIENTE\n",
        "            'spectral_searches': 0,   # ARMIJO N√ÉO USA BUSCAS ESPECTRAIS\n",
        "            'history': hist_arm\n",
        "        }\n",
        "        results.append(armijo_result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Erro em Armijo: {e}\")\n",
        "\n",
        "    # ------------------- GBB Raydan -------------------\n",
        "    try:\n",
        "        # Executa m√©todo GBB\n",
        "        x_opt_gbb, f_opt_gbb, hist_gbb, time_gbb, f_evals_gbb, g_evals_gbb, ls_gbb, ss_gbb = gbb_raydan(p, x0.copy())\n",
        "\n",
        "        final_iter_gbb = len(hist_gbb) - 1\n",
        "        final_norm_g_gbb = hist_gbb[-1][2] if hist_gbb else float('inf')\n",
        "\n",
        "        # Determinar estado de converg√™ncia\n",
        "        if final_norm_g_gbb <= 1e-6 * (1 + abs(f_opt_gbb)):\n",
        "            convergence_gbb = \"CONVERGIU\"\n",
        "        elif final_iter_gbb >= 10000:\n",
        "            convergence_gbb = \"EXCEDEU ITERA√á√ïES M√ÅXIMAS\"\n",
        "        elif hist_gbb and hist_gbb[-1][2] > 1e-3:\n",
        "            convergence_gbb = \"GRADIENTE N√ÉO PR√ìXIMO DE ZERO\"\n",
        "        else:\n",
        "            convergence_gbb = \"N√ÉO CONVERGIU\"\n",
        "\n",
        "        gbb_result = {\n",
        "            'method': 'GBB',\n",
        "            'iterations': final_iter_gbb,\n",
        "            'time': time_gbb,\n",
        "            'final_norm_g': final_norm_g_gbb,\n",
        "            'final_f': f_opt_gbb,\n",
        "            'convergence': convergence_gbb,\n",
        "            'f_evals': f_evals_gbb,\n",
        "            'g_evals': g_evals_gbb,\n",
        "            'line_searches': ls_gbb,\n",
        "            'spectral_searches': ss_gbb,  # BUSCAS ESPECTRAIS PARA GBB\n",
        "            'history': hist_gbb\n",
        "        }\n",
        "        results.append(gbb_result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Erro em GBB: {e}\")\n",
        "\n",
        "    # ===============================================================\n",
        "    # AN√ÅLISE COMPARATIVA\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"AN√ÅLISE COMPARATIVA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if results:\n",
        "        # Melhor modelo em itera√ß√µes\n",
        "        best_iter = min(results, key=lambda x: x['iterations'])\n",
        "        print(f\"\\nüèÜ MELHOR MODELO EM ITERA√á√ïES: {best_iter['method']}\")\n",
        "        print(f\"   Itera√ß√µes: {best_iter['iterations']}\")\n",
        "        print(f\"   Tempo: {best_iter['time']:.4f} segundos\")\n",
        "        print(f\"   Norma do gradiente: {best_iter['final_norm_g']:.3e}\")\n",
        "        if best_iter['method'] == 'Armijo':\n",
        "            print(f\"   Buscas lineares: {best_iter['line_searches']}\")  # PARA METODO DO GRADIENTE\n",
        "        else:\n",
        "            print(f\"   Buscas espectrais: {best_iter['spectral_searches']}\")  # PARA GBB\n",
        "        print(f\"   Estado: {best_iter['convergence']}\")\n",
        "\n",
        "        # Melhor modelo em tempo\n",
        "        best_time = min(results, key=lambda x: x['time'])\n",
        "        print(f\"\\n‚ö° MELHOR MODELO EM TEMPO: {best_time['method']}\")\n",
        "        print(f\"   Tempo: {best_time['time']:.4f} segundos\")\n",
        "        print(f\"   Itera√ß√µes: {best_time['iterations']}\")\n",
        "        print(f\"   Norma do gradiente: {best_time['final_norm_g']:.3e}\")\n",
        "        if best_time['method'] == 'Armijo':\n",
        "            print(f\"   Buscas lineares: {best_time['line_searches']}\")  # PARA METODO DO GRADIENTE\n",
        "        else:\n",
        "            print(f\"   Buscas espectrais: {best_time['spectral_searches']}\")  # PARA GBB\n",
        "        print(f\"   Estado: {best_time['convergence']}\")\n",
        "\n",
        "        # Melhor modelo em gradiente (mais pr√≥ximo de zero)\n",
        "        best_grad = min(results, key=lambda x: x['final_norm_g'])\n",
        "        print(f\"\\nüéØ MELHOR MODELO EM GRADIENTE: {best_grad['method']}\")\n",
        "        print(f\"   Norma do gradiente: {best_grad['final_norm_g']:.3e}\")\n",
        "        print(f\"   Itera√ß√µes: {best_grad['iterations']}\")\n",
        "        print(f\"   Tempo: {best_grad['time']:.4f} segundos\")\n",
        "        if best_grad['method'] == 'Armijo':\n",
        "            print(f\"   Buscas lineares: {best_grad['line_searches']}\")  # PARA METODO DO GRADIENTE\n",
        "        else:\n",
        "            print(f\"   Buscas espectrais: {best_grad['spectral_searches']}\")  # PARA GBB\n",
        "        print(f\"   Estado: {best_grad['convergence']}\")\n",
        "\n",
        "    # ===============================================================\n",
        "    # RESUMO FINAL\n",
        "    # ===============================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESUMO FINAL\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Fun√ß√£o avaliada: {p.name}\")\n",
        "    print(f\"Dimens√£o do problema: {dimension}\")\n",
        "    print(f\"Valor inicial f(x0): {f0:.6e}\")\n",
        "    print(f\"Norma inicial do gradiente: {np.linalg.norm(g0):.3e}\")\n",
        "\n",
        "    if results:\n",
        "        print(f\"\\nAlgoritmos avaliados: {len(results)}\")\n",
        "        for result in results:\n",
        "            print(f\"\\n{result['method']}:\")\n",
        "            print(f\"  ‚Ä¢ Itera√ß√µes: {result['iterations']}\")\n",
        "            print(f\"  ‚Ä¢ Tempo: {result['time']:.4f}s\")\n",
        "            print(f\"  ‚Ä¢ Norma gradiente: {result['final_norm_g']:.3e}\")\n",
        "            if result['method'] == 'Armijo':\n",
        "                print(f\"  ‚Ä¢ Buscas lineares: {result['line_searches']}\")  # PARA METODO DO GRADIENTE\n",
        "            else:\n",
        "                print(f\"  ‚Ä¢ Buscas espectrais: {result['spectral_searches']}\")  # PARA GBB\n",
        "            print(f\"  ‚Ä¢ Estado: {result['convergence']}\")\n",
        "            print(f\"  ‚Ä¢ Avalia√ß√µes de f: {result['f_evals']}\")\n",
        "            print(f\"  ‚Ä¢ Avalia√ß√µes de g: {result['g_evals']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Lista de problemas dispon√≠veis para teste:\n",
        "    #\"ARGLINA\", \"ARGLINB\", \"BA-L1SPLS\", \"BIGGS6\", \"BROWNAL\", \"COATING\",\n",
        "    #\"FLETCHCR\", \"GAUSS2LS\", \"GENROSE\", \"HAHN1LS\", \"HEART6LS\", \"HILBERTB\",\n",
        "    #\"HYDCAR6LS\", \"LANCZOS1LS\", \"LANCZOS2LS\", \"LRIJCNN1\", \"LUKSAN12LS\",\n",
        "    #\"LUKSAN16LS\", \"OSBORNEA\", \"PALMER1C\", \"PALMER3C\", \"PENALTY2\", \"PENALTY3\",\n",
        "    #\"QING\", \"ROSENBR\", \"STRTCHDV\", \"TESTQUAD\", \"THURBERLS\", \"TRIGON1\",\n",
        "    #\"TOINTGOR\n",
        "    resultados = run_cutest_optimization(\"ROSENBR\")"
      ]
    }
  ]
}